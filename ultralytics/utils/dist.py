# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import os
import shutil
import socket
import sys
import tempfile

from . import USER_CONFIG_DIR
from .torch_utils import TORCH_1_9


def find_free_network_port() -> int:
    """
    Finds a free port on localhost.

    It is useful in single-node training when we don't want to connect to a real main node but have to set the
    `MASTER_PORT` environment variable.
    """
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.bind(("127.0.0.1", 0))
        return s.getsockname()[1]  # port


def generate_ddp_file(trainer):
    """Generates a DDP file and returns its file name."""
    module, name = f"{trainer.__class__.__module__}.{trainer.__class__.__name__}".rsplit(".", 1)
    content = f"""
# Ultralytics Multi-GPU training temp file (should be automatically deleted after use)

import signal
from pathlib import Path
import sys
def handler(signum, frame):
    # ç»ˆæ­¢æ•´ä¸ªè¿›ç¨‹ç»„
    print(f'[SIGINT] Terminating process group...')
    if torch.distributed.is_initialized():
        torch.distributed.destroy_process_group()  # é‡Šæ”¾åˆ†å¸ƒå¼èµ„æº
    os.killpg(os.getpgid(os.getpid()), signal.SIGKILL)  # æ€æ­»æ•´ä¸ªè¿›ç¨‹ç»„
    sys.exit(1)

signal.signal(signal.SIGINT, handler)

overrides = {vars(trainer.args)}
import os
import argparse  # æ–°å¢argparseæ¨¡å—
# ... åŸæœ‰è·¯å¾„è®¾ç½®ä¿æŒä¸å˜ ...
FILE = Path(__file__).resolve()
ROOT = FILE.parents[1]  # YOLOv5 root directory
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))
from {module} import {name}
from ultralytics.utils import DEFAULT_CFG_DICT
if __name__ == "__main__":
    try:
        cfg = DEFAULT_CFG_DICT.copy()
        cfg.update(save_dir='')   # handle the extra key 'save_dir'
        trainer = {name}(cfg=cfg, overrides=overrides)
        trainer.args.model = "{getattr(trainer.hub_session, "model_url", trainer.args.model)}"
        results = trainer.train()
    finally:
        # ç¡®ä¿é‡Šæ”¾åˆ†å¸ƒå¼èµ„æº
        if torch.distributed.is_initialized():
            torch.distributed.destroy_process_group()
"""
    with tempfile.NamedTemporaryFile(
        prefix="_temp_",
        suffix=f"{id(trainer)}.py",
        mode="w+",
        encoding="utf-8",
        dir=".",
        delete=False,
    ) as file:
        file.write(content)
        if hasattr(os, 'register_at_fork'):
            os.register_at_fork(after_in_child=lambda: os.remove(file.name))
    return file.name


def generate_ddp_command(world_size, trainer):
    """Generates and returns command for distributed training."""
    import __main__  # noqa local import to avoid https://github.com/Lightning-AI/lightning/issues/15218

    if not trainer.resume:
        shutil.rmtree(trainer.save_dir)  # remove the save_dir
    file = generate_ddp_file(trainer)
    dist_cmd = "torch.distributed.run" if TORCH_1_9 else "torch.distributed.launch"
    port = find_free_network_port()
    cmd = [sys.executable,
           "-u",  # æ— ç¼“å†²è¾“å‡º
           "-m", dist_cmd,
           "--nproc_per_node",  f"{world_size}",
           "--master_port",  f"{port}",
           file
    ]
    return cmd, file

def kill_related_processes(file: str):
    """è·¨å¹³å°ç»ˆæ­¢ä¸ä¸´æ—¶æ–‡ä»¶ç›¸å…³çš„è¿›ç¨‹"""
    if sys.platform == "win32":
        # Windows ä½¿ç”¨ tasklist å’Œ taskkill
        import subprocess
        try:
            # æŸ¥æ‰¾åŒ…å«æ–‡ä»¶åçš„è¿›ç¨‹
            result = subprocess.run(
                f'tasklist /FI "IMAGENAME eq python*" /FO CSV /NH',
                capture_output=True,
                text=True,
                shell=True,
                check=True)
            # è§£æè¿›ç¨‹PID
            pids = [line.split(',')[1].strip('"')
                   for line in result.stdout.splitlines()
                   if file in line]
            # ç»ˆæ­¢è¿›ç¨‹
            for pid in pids:
                subprocess.run(f"taskkill /F /PID {pid}", shell=True, check=True)
        except subprocess.CalledProcessError:
            pass
    else:
        # Linux/Mac ä½¿ç”¨ pgrep/pkill
        import subprocess
        try:
            subprocess.run(f"pkill -f {file}", shell=True, check=True)
        except subprocess.CalledProcessError:
            pass

def ddp_cleanup(trainer, file):
    """Delete temp file if created."""
    # å…ˆç»ˆæ­¢ç›¸å…³è¿›ç¨‹
    kill_related_processes(file)
    # å†åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    if f"{id(trainer)}.py" in file:  # if temp_file suffix in file
        os.remove(file)
